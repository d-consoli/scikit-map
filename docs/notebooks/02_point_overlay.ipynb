{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use the eumap package to overlay all the points of a vector layer (*geopackage file*) on several raster layers (*geotiff files*), using the **SpaceOverlay** and **SpaceTimeOverlay** classes to handle with timeless and temporal layers, respectively. \n",
    "\n",
    "In our dataset the elevation and slope, based on digital terrain model, are timeless and the landsat composites (7 spectral bands, 4 seasons and 3 percentiles) and night light (VIIRS Night Band) layers are temporal (from 2000 to 2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with local eumap code\n",
    "# import sys\n",
    "# sys.path.append('../../')\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from eumap.mapper import SpaceOverlay, SpaceTimeOverlay\n",
    "from eumap.misc import find_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset refers to one tile, located in Switzerland, extracted from a tiling system created for Continental Europe (7,042 tiles) by [GeoHarmonizer Project](https://opendatascience.eu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eumap import datasets\n",
    "\n",
    "# Clean the files from the previous tutorial\n",
    "#shutil.rmtree(datasets.DATA_ROOT_NAME, ignore_errors=False, onerror=None)\n",
    "\n",
    "tile = datasets.pilot.TILES[0]\n",
    "#datasets.pilot.get_data(tile+'_rasters_gapfilled.tar.gz')\n",
    "\n",
    "data_root = datasets.DATA_ROOT_NAME\n",
    "tile_dir = Path(os.getcwd()).joinpath(data_root, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tile we have a **geopackage** file containing the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/geodataframe.py:577: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lucas</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>confidence</th>\n",
       "      <th>tile_id</th>\n",
       "      <th>lc_class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4145221.759 2594636.440)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4142366.664 2598169.380)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4140249.007 2596954.755)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>322</td>\n",
       "      <td>POINT (4148638.412 2595538.585)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>332</td>\n",
       "      <td>POINT (4156286.754 2595790.720)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>333</td>\n",
       "      <td>POINT (4141257.016 2584469.100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>111</td>\n",
       "      <td>POINT (4141241.654 2581611.485)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>312</td>\n",
       "      <td>POINT (4140414.076 2582953.315)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>324</td>\n",
       "      <td>POINT (4140716.302 2580458.165)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>False</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>111</td>\n",
       "      <td>POINT (4141241.654 2581611.485)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lucas survey_date  confidence  tile_id  lc_class  \\\n",
       "0     False  2006-06-30          85    10636       321   \n",
       "1     False  2006-06-30          85    10636       321   \n",
       "2     False  2006-06-30          85    10636       321   \n",
       "3     False  2006-06-30          85    10636       322   \n",
       "4     False  2006-06-30          85    10636       332   \n",
       "...     ...         ...         ...      ...       ...   \n",
       "1119  False  2006-06-30          85    10636       333   \n",
       "1120  False  2006-06-30          85    10636       111   \n",
       "1121  False  2006-06-30          85    10636       312   \n",
       "1122  False  2006-06-30          85    10636       324   \n",
       "1123  False  2012-06-30          85    10636       111   \n",
       "\n",
       "                             geometry  \n",
       "0     POINT (4145221.759 2594636.440)  \n",
       "1     POINT (4142366.664 2598169.380)  \n",
       "2     POINT (4140249.007 2596954.755)  \n",
       "3     POINT (4148638.412 2595538.585)  \n",
       "4     POINT (4156286.754 2595790.720)  \n",
       "...                               ...  \n",
       "1119  POINT (4141257.016 2584469.100)  \n",
       "1120  POINT (4141241.654 2581611.485)  \n",
       "1121  POINT (4140414.076 2582953.315)  \n",
       "1122  POINT (4140716.302 2580458.165)  \n",
       "1123  POINT (4141241.654 2581611.485)  \n",
       "\n",
       "[1124 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datasets.pilot.get_data(tile+'_landcover_samples.gpkg')\n",
    "\n",
    "fn_points = Path(os.getcwd()).joinpath(data_root, tile, tile+'_landcover_samples.gpkg')\n",
    "\n",
    "points = gpd.read_file(fn_points)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... some **timeless** raster layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timeless layers: 2\n"
     ]
    }
   ],
   "source": [
    "dir_timeless_layers = os.path.join(tile_dir, 'timeless')\n",
    "fn_timeless_layers = find_files(dir_timeless_layers, '*.tif')\n",
    "\n",
    "print(f'Number of timeless layers: {len(fn_timeless_layers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and several **temporal** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722 temporal layers from 2000 to 2020\n"
     ]
    }
   ],
   "source": [
    "dir_temporal_layers = os.path.join(tile_dir)\n",
    "fn_temporal_layers = find_files(dir_temporal_layers, 'landsat*.tif')\n",
    "\n",
    "print(f'{len(fn_temporal_layers)} temporal layers from 2000 to 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association between the points and the temporal layers will occurs using the **survey_date** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples per year:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2006    281\n",
       "2012    281\n",
       "2018    281\n",
       "2000    281\n",
       "Name: survey_date, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_date = 'survey_date'\n",
    "\n",
    "print('Number of samples per year:')\n",
    "pd.to_datetime(points[col_date]).dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the name of **temporal** directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal directories:\n",
      " - 2000: 84 layers\n",
      " - 2001: 84 layers\n",
      " - 2002: 84 layers\n",
      " - 2003: 84 layers\n",
      " - 2004: 84 layers\n",
      " - 2005: 84 layers\n",
      " - 2006: 84 layers\n",
      " - 2007: 84 layers\n",
      " - 2008: 84 layers\n",
      " - 2009: 84 layers\n",
      " - 2010: 84 layers\n",
      " - 2011: 84 layers\n",
      " - 2012: 84 layers\n",
      " - 2013: 84 layers\n",
      " - 2014: 84 layers\n",
      " - 2015: 84 layers\n",
      " - 2016: 84 layers\n",
      " - 2017: 84 layers\n",
      " - 2018: 84 layers\n",
      " - 2019: 84 layers\n",
      " - 2020: 42 layers\n"
     ]
    }
   ],
   "source": [
    "dirs = find_files(dir_temporal_layers, '????')\n",
    "dirs.sort()\n",
    "\n",
    "print('Temporal directories:')\n",
    "for dir in dirs:\n",
    "    year_dir = Path(os.path.join(dir_temporal_layers,dir))\n",
    "    n_layers = len(find_files(year_dir, 'landsat*.tif'))\n",
    "    print(f' - {dir.name}: {n_layers} layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points should be overlayed on all timeless layers, regardless the date information stored in survey_date column. In this case, we will use the **SpaceOverlay** class passing the arguments:\n",
    "\n",
    "- *fn_points*: the geopackage filepath\n",
    "- *dir_timeless_layers*: the directory containing the timeless raster files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/geodataframe.py:577: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:08] 1/2 dtm_elevation\n",
      "[15:19:08] 2/2 dtm_slope\n"
     ]
    }
   ],
   "source": [
    "spc_overlay = SpaceOverlay(fn_points, dir_layers=dir_timeless_layers, verbose=True)\n",
    "timeless_data = spc_overlay.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the elevation and slope information for each points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lucas</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>confidence</th>\n",
       "      <th>tile_id</th>\n",
       "      <th>lc_class</th>\n",
       "      <th>geometry</th>\n",
       "      <th>overlay_id</th>\n",
       "      <th>dtm_elevation</th>\n",
       "      <th>dtm_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4145221.759 2594636.440)</td>\n",
       "      <td>1</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>36.313705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4142366.664 2598169.380)</td>\n",
       "      <td>2</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>7.917305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4140249.007 2596954.755)</td>\n",
       "      <td>3</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>32.722038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>322</td>\n",
       "      <td>POINT (4148638.412 2595538.585)</td>\n",
       "      <td>4</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>49.800537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>332</td>\n",
       "      <td>POINT (4156286.754 2595790.720)</td>\n",
       "      <td>5</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>27.018671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>333</td>\n",
       "      <td>POINT (4141257.016 2584469.100)</td>\n",
       "      <td>1120</td>\n",
       "      <td>2368.0</td>\n",
       "      <td>21.605083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>111</td>\n",
       "      <td>POINT (4141241.654 2581611.485)</td>\n",
       "      <td>1121</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>20.821150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>312</td>\n",
       "      <td>POINT (4140414.076 2582953.315)</td>\n",
       "      <td>1122</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>16.108473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>324</td>\n",
       "      <td>POINT (4140716.302 2580458.165)</td>\n",
       "      <td>1123</td>\n",
       "      <td>900.0</td>\n",
       "      <td>27.319332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>False</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>111</td>\n",
       "      <td>POINT (4141241.654 2581611.485)</td>\n",
       "      <td>1124</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>20.821150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lucas survey_date  confidence  tile_id  lc_class  \\\n",
       "0     False  2006-06-30          85    10636       321   \n",
       "1     False  2006-06-30          85    10636       321   \n",
       "2     False  2006-06-30          85    10636       321   \n",
       "3     False  2006-06-30          85    10636       322   \n",
       "4     False  2006-06-30          85    10636       332   \n",
       "...     ...         ...         ...      ...       ...   \n",
       "1119  False  2006-06-30          85    10636       333   \n",
       "1120  False  2006-06-30          85    10636       111   \n",
       "1121  False  2006-06-30          85    10636       312   \n",
       "1122  False  2006-06-30          85    10636       324   \n",
       "1123  False  2012-06-30          85    10636       111   \n",
       "\n",
       "                             geometry  overlay_id  dtm_elevation  dtm_slope  \n",
       "0     POINT (4145221.759 2594636.440)           1         1948.0  36.313705  \n",
       "1     POINT (4142366.664 2598169.380)           2         2209.0   7.917305  \n",
       "2     POINT (4140249.007 2596954.755)           3         1990.0  32.722038  \n",
       "3     POINT (4148638.412 2595538.585)           4         2142.0  49.800537  \n",
       "4     POINT (4156286.754 2595790.720)           5         2420.0  27.018671  \n",
       "...                               ...         ...            ...        ...  \n",
       "1119  POINT (4141257.016 2584469.100)        1120         2368.0  21.605083  \n",
       "1120  POINT (4141241.654 2581611.485)        1121         1249.0  20.821150  \n",
       "1121  POINT (4140414.076 2582953.315)        1122         1729.0  16.108473  \n",
       "1122  POINT (4140716.302 2580458.165)        1123          900.0  27.319332  \n",
       "1123  POINT (4141241.654 2581611.485)        1124         1249.0  20.821150  \n",
       "\n",
       "[1124 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeless_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space-Time Overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the temporal layers, the points should be filtered by year and overlaid on the right raster files, perfoming the overlay with all the images from a specific year. The **SpaceTimeOverlay** class implements this approach using the parameter:\n",
    "\n",
    "* *timeless_data*: The result of SpaceOverlay (GeoPandas DataFrame) \n",
    "* *col_date*: The column that contains the date information (2018-09-13)\n",
    "* *dir_temporal_layers*: The directory where the temporal raster files are stored, organized by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_layers = [ str(file).replace('2000', '{year}') for file in find_files(dir_temporal_layers, '2000/*.tif') ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "spc_time_Overlay = SpaceTimeOverlay(points=timeless_data, col_date=col_date, \\\n",
    "    fn_layers=fn_layers, verbose=False)\n",
    "overlayed_data = spc_time_Overlay.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the elevation, slope, landsat and the night light data for each points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lucas</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>confidence</th>\n",
       "      <th>tile_id</th>\n",
       "      <th>lc_class</th>\n",
       "      <th>geometry</th>\n",
       "      <th>overlay_id</th>\n",
       "      <th>dtm_elevation</th>\n",
       "      <th>dtm_slope</th>\n",
       "      <th>landsat_ard_fall_nir_p25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4145221.759 2594636.440)</td>\n",
       "      <td>1</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>36.313705</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4142366.664 2598169.380)</td>\n",
       "      <td>2</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>7.917305</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4140249.007 2596954.755)</td>\n",
       "      <td>3</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>32.722038</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>322</td>\n",
       "      <td>POINT (4148638.412 2595538.585)</td>\n",
       "      <td>4</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>49.800537</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>332</td>\n",
       "      <td>POINT (4156286.754 2595790.720)</td>\n",
       "      <td>5</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>27.018671</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>False</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>312</td>\n",
       "      <td>POINT (4140414.076 2582953.315)</td>\n",
       "      <td>277</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>16.108473</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>False</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>332</td>\n",
       "      <td>POINT (4157045.539 2609917.600)</td>\n",
       "      <td>278</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>31.661921</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>False</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>321</td>\n",
       "      <td>POINT (4141237.722 2583848.400)</td>\n",
       "      <td>279</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>15.649096</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>False</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>333</td>\n",
       "      <td>POINT (4141257.016 2584469.100)</td>\n",
       "      <td>280</td>\n",
       "      <td>2368.0</td>\n",
       "      <td>21.605083</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>False</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>85</td>\n",
       "      <td>10636</td>\n",
       "      <td>322</td>\n",
       "      <td>POINT (4140716.302 2580458.165)</td>\n",
       "      <td>281</td>\n",
       "      <td>900.0</td>\n",
       "      <td>27.319332</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lucas survey_date  confidence  tile_id  lc_class  \\\n",
       "0     False  2006-06-30          85    10636       321   \n",
       "1     False  2006-06-30          85    10636       321   \n",
       "2     False  2006-06-30          85    10636       321   \n",
       "3     False  2006-06-30          85    10636       322   \n",
       "4     False  2006-06-30          85    10636       332   \n",
       "...     ...         ...         ...      ...       ...   \n",
       "1098  False  2000-06-30          85    10636       312   \n",
       "1112  False  2000-06-30          85    10636       332   \n",
       "1115  False  2000-06-30          85    10636       321   \n",
       "1116  False  2000-06-30          85    10636       333   \n",
       "1117  False  2000-06-30          85    10636       322   \n",
       "\n",
       "                             geometry  overlay_id  dtm_elevation  dtm_slope  \\\n",
       "0     POINT (4145221.759 2594636.440)           1         1948.0  36.313705   \n",
       "1     POINT (4142366.664 2598169.380)           2         2209.0   7.917305   \n",
       "2     POINT (4140249.007 2596954.755)           3         1990.0  32.722038   \n",
       "3     POINT (4148638.412 2595538.585)           4         2142.0  49.800537   \n",
       "4     POINT (4156286.754 2595790.720)           5         2420.0  27.018671   \n",
       "...                               ...         ...            ...        ...   \n",
       "1098  POINT (4140414.076 2582953.315)         277         1729.0  16.108473   \n",
       "1112  POINT (4157045.539 2609917.600)         278         2562.0  31.661921   \n",
       "1115  POINT (4141237.722 2583848.400)         279         2174.0  15.649096   \n",
       "1116  POINT (4141257.016 2584469.100)         280         2368.0  21.605083   \n",
       "1117  POINT (4140716.302 2580458.165)         281          900.0  27.319332   \n",
       "\n",
       "      landsat_ard_fall_nir_p25  \n",
       "0                         65.0  \n",
       "1                         76.0  \n",
       "2                         69.0  \n",
       "3                         16.0  \n",
       "4                         66.0  \n",
       "...                        ...  \n",
       "1098                      55.0  \n",
       "1112                      25.0  \n",
       "1115                      77.0  \n",
       "1116                      62.0  \n",
       "1117                      70.0  \n",
       "\n",
       "[1124 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlayed_data[overlayed_data.columns[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV and GeoPackage files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we need to save the overlaid points to access it in other softwares (QGIS) and eumap tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /home/opengeohub/leandro/Code/eumap/docs/notebooks/eumap_data/10636_switzerland/10636_switzerland_landcover_samples_overlayed.csv.gz\n"
     ]
    }
   ],
   "source": [
    "csv_output = os.path.join(tile_dir, tile + '_landcover_samples_overlayed.csv.gz')\n",
    "\n",
    "print(f\"Saving {csv_output}\")\n",
    "overlayed_data.to_csv(csv_output, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /home/opengeohub/leandro/Code/eumap/docs/notebooks/eumap_data/10636_switzerland/10636_switzerland_landcover_samples_overlayed.gpkg\n"
     ]
    }
   ],
   "source": [
    "import fiona \n",
    "\n",
    "#See https://github.com/Toblerity/Fiona/issues/977\n",
    "with fiona.Env(OSR_WKT_FORMAT=\"WKT2_2018\"):\n",
    "    gpkg_output =  os.path.join(tile_dir, tile + '_landcover_samples_overlayed.gpkg')\n",
    "\n",
    "    print(f\"Saving {gpkg_output}\")\n",
    "    overlayed_data.to_file(gpkg_output,  driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay Benchmarks\n",
    "\n",
    "Here we will show the performance of `eumap`'s overlay method against classic raster sampling methods using `rasterio`. First, let's time the overlay executions on the same dataset as in the tutorial above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 1124\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from eumap.mapper import SpaceOverlay\n",
    "\n",
    "max_workers = 8\n",
    "\n",
    "points = gpd.read_file(fn_points)\n",
    "print('Sample size:', points.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serial sampling with `rasterio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 49s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def serial_sampling(points, layers_dir):\n",
    "    sources = [\n",
    "        rio.open(fn)\n",
    "        for fn in sorted(layers_dir.glob('**/*.tif'))\n",
    "    ]\n",
    "\n",
    "    coordinates = np.c_[\n",
    "        points.geometry.x,\n",
    "        points.geometry.y,\n",
    "    ]\n",
    "\n",
    "    results = points.copy()\n",
    "    for src in sources:\n",
    "        layer_name = Path(src.name).stem\n",
    "        results[layer_name] = np.stack(src.sample(coordinates)).ravel()\n",
    "\n",
    "%timeit -n 1 -r 1 serial_sampling(points, tile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel sampling with `rasterio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.9 s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def sample_one_layer(args):\n",
    "    fn, coordinates = args\n",
    "    layer_name = fn.stem\n",
    "    with rio.open(fn) as src:\n",
    "        data = np.stack(src.sample(coordinates)).ravel()\n",
    "    return layer_name, data\n",
    "\n",
    "def parallel_sampling(points, layers_dir):\n",
    "    files = sorted(layers_dir.glob('**/*.tif'))\n",
    "\n",
    "    coordinates = np.c_[\n",
    "        points.geometry.x,\n",
    "        points.geometry.y,\n",
    "    ]\n",
    "\n",
    "    results = points.copy()\n",
    "\n",
    "    arg_gen = (\n",
    "        (fn, coordinates)\n",
    "        for fn in files\n",
    "    )\n",
    "\n",
    "    with mp.Pool(max_workers) as pool:\n",
    "        for layer_name, data in pool.map(\n",
    "            sample_one_layer,\n",
    "            arg_gen,\n",
    "        ):\n",
    "            results[layer_name] = data\n",
    "\n",
    "%timeit -n 1 -r 1 parallel_sampling(points, tile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel sampling with `eumap.mapper.SpaceOverlay`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 52s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def eumap_sampling(points, layers_dir):\n",
    "    ovr = SpaceOverlay(\n",
    "        points,\n",
    "        dir_layers=layers_dir,\n",
    "        max_workers=max_workers,\n",
    "        verbose=False,\n",
    "    )\n",
    "    data = ovr.run()\n",
    "\n",
    "%timeit -n 1 -r 1 eumap_sampling(points, tile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling optimizations done in `eumap` generate some overhead which outweighs the speedup when used on smaller datasets. However, if we quadruple the sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 4496\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    points = points.append(points, ignore_index=True)\n",
    "\n",
    "print('sample size:', points.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel sampling with `rasterio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 57s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 parallel_sampling(points, tile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel sampling with `eumap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 55s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 eumap_sampling(points, tile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the optimized overlay's execution time has much more favorable scaling with dataset size than is the case with raw parallelization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
