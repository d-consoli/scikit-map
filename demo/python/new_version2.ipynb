{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import os\n",
    "import gdal\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyeumap.mapper import LandMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeumap import datasets\n",
    "\n",
    "tile = datasets.TILES[0]\n",
    "\n",
    "data_root = datasets.DATA_ROOT_NAME\n",
    "data_dir = Path(os.getcwd()).joinpath(data_root,tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_points = data_dir.joinpath(f'{tile}_landcover_samples_overlayed.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyeumap.misc import build_ann\n",
    "\n",
    "estimator_rf = RandomForestClassifier(n_jobs=-1, n_estimators=85)\n",
    "estimator_bgtree = xgb.XGBClassifier(n_jobs=-1, n_estimators=28, objective='multi:softmax', eval_metric='mlogloss', booster='gbtree')\n",
    "\n",
    "input_shape = 87\n",
    "n_classes = 8\n",
    "estimator_ann = Pipeline([\n",
    "\t('standardize', StandardScaler()),\n",
    "\t('estimator', KerasClassifier(build_ann, input_shape=input_shape, output_shape=n_classes, \\\n",
    "\t\tepochs=5, batch_size=64, learning_rate = 0.0005, \\\n",
    "\t\tdropout_rate=0.15, n_layers = 4, n_neurons=64, shuffle=True, verbose=False))\n",
    "])\n",
    "\n",
    "meta_estimator = LogisticRegression(solver='saga', multi_class='multinomial', n_jobs=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def log_loss_scorer(clf, X, y_true):\n",
    "    class_labels = clf.classes_\n",
    "    y_pred_proba = clf.predict_proba(X)\n",
    "    error = log_loss(y_true, y_pred_proba, labels=class_labels)\n",
    "    return error * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperpar_rf = GridSearchCV(\n",
    "    estimator = estimator_rf,\n",
    "    scoring = 'accuracy',\n",
    "    param_grid = {\n",
    "     'max_depth': [5, None], \n",
    "     'max_features': [0.5, None]\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperpar_bgtree = GridSearchCV(\n",
    "    estimator = estimator_bgtree,\n",
    "    scoring = 'accuracy',\n",
    "    param_grid = {\n",
    "     'eta': [0.001, 0.9], \n",
    "     'alpha': [0, 10]\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperpar_ann = GridSearchCV(\n",
    "    estimator = estimator_ann,\n",
    "    scoring = 'accuracy',\n",
    "    param_grid = {\n",
    "     'estimator__dropout_rate': [0, 0.15], \n",
    "     'estimator__n_layers': [2, 4]\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperpar_meta = GridSearchCV(\n",
    "    estimator = meta_estimator,\n",
    "    scoring = 'accuracy',\n",
    "    param_grid = {\n",
    "        'fit_intercept': [False, True],\n",
    "        'C': [0.5, 1]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (single estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#feat_col_prfxs = ['landsat', 'dtm', 'night_lights']\n",
    "#target_col = 'lc_class'\n",
    "\n",
    "#landmapper = LandMapper(points=fn_points, \n",
    "#                        feat_col_prfxs = feat_col_prfxs, \n",
    "#                        target_col = target_col, \n",
    "#                        estimator = estimator_rf, \n",
    "#                        hyperpar_selection = hyperpar_rf,\n",
    "#                        min_samples_per_class=0.05,\n",
    "#                        cv=2,\n",
    "#                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#landmapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(landmapper.eval_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (single estimator - prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#feat_col_prfxs = ['landsat', 'dtm', 'night_lights']\n",
    "#target_col = 'lc_class'\n",
    "\n",
    "#landmapper = LandMapper(points=fn_points, \n",
    "#                        feat_col_prfxs = feat_col_prfxs, \n",
    "#                        target_col = target_col, \n",
    "#                        estimator = estimator_rf, \n",
    "#                        hyperpar_selection = hyperpar_rf,\n",
    "#                        min_samples_per_class=0.05,\n",
    "#                        cv=2,\n",
    "#                        pred_method='predict_proba',\n",
    "#                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#landmapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(landmapper.eval_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Ensemble Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:30] Removing 74 samples due min_samples_per_class condition (< 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_col_prfxs = ['landsat', 'dtm', 'night_lights']\n",
    "target_col = 'lc_class'\n",
    "\n",
    "estimator_list = [estimator_rf, estimator_bgtree, estimator_ann]\n",
    "hyperpar_selection_list = [hyperpar_rf, hyperpar_bgtree, hyperpar_ann]\n",
    "\n",
    "landmapper = LandMapper(points=fn_points, \n",
    "                        feat_col_prfxs = feat_col_prfxs, \n",
    "                        target_col = target_col, \n",
    "                        estimator_list = estimator_list, \n",
    "                        meta_estimator = meta_estimator,\n",
    "                        hyperpar_selection_list = hyperpar_selection_list,\n",
    "                        hyperpar_selection_meta = hyperpar_meta,\n",
    "                        min_samples_per_class=0.05,\n",
    "                        cv=2,\n",
    "                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:30] Optimizing hyperparameters for RandomForestClassifier\n",
      "[10:16:35]  -0.63143 (+/-0.02476) from {'max_depth': 5, 'max_features': 0.5}\n",
      "[10:16:35]  -0.63238 (+/-0.00381) from {'max_depth': 5, 'max_features': None}\n",
      "[10:16:35]  -0.72190 (+/-0.00381) from {'max_depth': None, 'max_features': 0.5}\n",
      "[10:16:35]  -0.73048 (+/-0.02476) from {'max_depth': None, 'max_features': None}\n",
      "[10:16:35] Best: 0.73048 using {'max_depth': None, 'max_features': None}\n",
      "[10:16:35] Optimizing hyperparameters for XGBClassifier\n",
      "[10:16:40]  -0.59048 (+/-0.03048) from {'alpha': 0, 'eta': 0.001}\n",
      "[10:16:40]  -0.70571 (+/-0.05905) from {'alpha': 0, 'eta': 0.9}\n",
      "[10:16:40]  -0.55238 (+/-0.04571) from {'alpha': 10, 'eta': 0.001}\n",
      "[10:16:40]  -0.60857 (+/-0.01333) from {'alpha': 10, 'eta': 0.9}\n",
      "[10:16:40] Best: 0.70571 using {'alpha': 0, 'eta': 0.9}\n",
      "[10:16:40] Optimizing hyperparameters for Pipeline\n",
      "[10:17:13]  -0.42476 (+/-0.01143) from {'estimator__dropout_rate': 0, 'estimator__n_layers': 2}\n",
      "[10:17:13]  -0.22762 (+/-0.20000) from {'estimator__dropout_rate': 0, 'estimator__n_layers': 4}\n",
      "[10:17:13]  -0.45429 (+/-0.00190) from {'estimator__dropout_rate': 0.15, 'estimator__n_layers': 2}\n",
      "[10:17:13]  -0.35810 (+/-0.11048) from {'estimator__dropout_rate': 0.15, 'estimator__n_layers': 4}\n",
      "[10:17:13] Best: 0.45429 using {'estimator__dropout_rate': 0.15, 'estimator__n_layers': 2}\n",
      "[10:17:13] Calculating meta-features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:17:22]  Meta-features shape: (1050, 24)\n",
      "[10:17:22] Optimizing hyperparameters for LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:17:24]  -0.71333 (+/-0.00952) from {'C': 0.5, 'fit_intercept': False}\n",
      "[10:17:24]  -0.71429 (+/-0.00762) from {'C': 0.5, 'fit_intercept': True}\n",
      "[10:17:24]  -0.71238 (+/-0.01143) from {'C': 1, 'fit_intercept': False}\n",
      "[10:17:24]  -0.70952 (+/-0.00571) from {'C': 1, 'fit_intercept': True}\n",
      "[10:17:24] Best: 0.71429 using {'C': 0.5, 'fit_intercept': True}\n",
      "[10:17:24] Calculating evaluation metrics\n",
      "[10:17:24] Training RandomForestClassifier using all samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:17:24] Training XGBClassifier using all samples\n",
      "[10:17:25] Training Pipeline using all samples\n",
      "[10:17:28] Training meta-estimator using all samples\n"
     ]
    }
   ],
   "source": [
    "landmapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log_loss': 0.8713499966119077}\n"
     ]
    }
   ],
   "source": [
    "print(landmapper.eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/leandro/Code/eumap/demo/python/eumap_data/10636_switzerland/10636_switzerland_landmapper.mod']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_model = data_dir.joinpath(f'{tile}_landmapper.mod')\n",
    "landmapper.save_instance(fn_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
